#!/usr/bin/env python

import os
import sys
import pickle

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.mlab as mlab

import logging
import optparse
import subprocess

## Arguments: General options 
parser = optparse.OptionParser()
parser.add_option('-v', dest='verbose', action="count", 
                  help='Show debug information')
parser.add_option('-x', dest='limit', type="int",
                  help='Limit the number of pairs to read per input file')
parser.add_option('--skip_read' , dest='skipRead', action="store_true",
                  help='Skip reading the BAM files, read the parsed BAM files ' + 
                  'directly from disk')
parser.add_option('--skip_stats' , dest='skipStat', action="store_true",
                  help='Skip stat creating, read the stat data from disk')

options, args = parser.parse_args()
inputFiles = args
l = logging.getLogger('hagfish')
handler = logging.StreamHandler()
logmark = chr(27) + '[0;37;44mHAGFISH' + \
          chr(27) + '[0m ' 

formatter = logging.Formatter(
    logmark + '%(levelname)-6s %(message)s')

handler.setFormatter(formatter)
l.addHandler(handler)

if options.verbose >= 2:
    l.setLevel(logging.DEBUG)
elif options.verbose == 1:
    l.setLevel(logging.INFO)
else:
    l.setLevel(logging.WARNING)

def run(cl):
    return subprocess.Popen(cl.split(), 
                         stdout=subprocess.PIPE, 
                         stderr=subprocess.PIPE)

def runReturn(cl):
    return run(cl).communicate()[0].split('\n')

def getSequenceInfo(inputFile):
    seqInfo = {}
    for line in runReturn('samtools view -H %s' % inputFile):
        line = line.strip()
        if not line: continue
        if line[:3] == '@SQ':
            ls = line.split()
            seqId = ls[1][3:]
            seqLen = int(ls[2][3:])
            if not seqInfo.has_key(seqId):
                seqInfo[seqId] = { 'length' : seqLen }
            else:
                if seqInfo[seqId]['length'] != seqLen:
                    raise(Exception("problem with seqlen"))
                seqInfo[seqId]['seenIn'].append(inputFile)
    return seqInfo
    
def readBAM(fileName):
    p = run("samtools view -f 2 %s" % fileName)
    while True:
        line1 = p.stdout.readline()
        if not line1: break
        line1 = line1.strip()
        if not line1: continue
        if line1[0] == '@': continue
        line2 = p.stdout.readline()

        l1 = line1.split()
        l2 = line2.split()

        rl = len(l1[9])
        seqid = l1[2]
        start1 = int(l1[3])
        stop1 = start1 + rl
        start2 = int(l2[3])
        stop2 = start2 + rl

        yield seqid, start1, stop1, start2, stop2, 

def smoother(a, steps):
    result = np.zeros(len(a) - steps + 1)
    for fr in range(steps):
        to = - (steps - fr - 1)
        if to == 0: to = None
        result += a[fr:to]        
    return result / float(steps)

def doStats(bamname, seqInfo, readPairs):

    if not os.path.exists('stats'):
        os.mkdir('stats')
    stats = {}

    # concatenate all insertsizes of all readpairs of all sequences for
    # this single bamfile into one
    insertSizes = np.concatenate(
        [readPairs[s]['stop2'] - readPairs[s]['start1'] for 
         s in readPairs.keys()])

    l.info("total no readpairs: %d" % len(insertSizes))

    stats['nopairs'] = len(insertSizes)
    stats['median'] = np.median(insertSizes)
    stats['average'] = np.average(insertSizes)

    # generate a histogram
    hist, edges = np.histogram(insertSizes, bins=500, range=(0, 30000), new=True)
    mids = 0.5 * (edges[1:] + edges[:-1])

    #smooth the histogram (using a moving average)
    shist = smoother(hist, 10)
    smids = smoother(mids, 10)
    
    # find the top of the peak
    top = np.argmax(shist)
    topInsert = smids[top]
    stats['top'] = topInsert
    l.info("insert size tops at %s" % topInsert)
    smoothMax = np.max(shist)

    #find the left & right borders of the peak
    leftB = top-1
    while (shist[leftB] > (0.1 * smoothMax)) and \
            (shist[leftB-1] < shist[leftB]) and \
            leftB > 0: leftB -= 1
    topLeft = smids[leftB]

    rghtB = top+1
    while (shist[rghtB] > (0.1 * smoothMax)) and \
            (shist[rghtB+1] < shist[rghtB]) and \
            rghtB < len(shist): rghtB += 1
    topRight = smids[rghtB]        
    stats['left'] = topLeft
    stats['right'] = topRight

    # plot a figure
    l.info('plotting figure')
    fig = plt.figure()
    ax = fig.add_subplot(111)
    plt.title('Insert size distribution for %s' % bamname,
              fontdict={'size' : 10})
    ax.plot(smids, shist, '#8888ff', linewidth=5,
            label = "Smoothed histogram")
    ax.plot(mids, hist, 'red', label='histogram')
    minY, maxY = ax.get_axes().get_ylim()

    ax.vlines(topInsert,minY,maxY, 'g',  linestyles='dotted',
              label='Peak top')
    ax.vlines(topLeft,minY,maxY, 'b', linestyles='dotted', 
              label='left border peak')
    ax.vlines(topRight,minY,maxY, 'r', linestyles='dotted', 
              label='rigth border peak')

    ax.legend(prop={'size' :'x-small'})
    plt.savefig(os.path.join('stats', bamname + '.hist.png'))

    #write stats file for this library
    with open(os.path.join('stats', bamname + '.stats'), 'w') as F:
        for k in stats.keys():
            l.debug("stat %s : %s" % (k, stats[k]))
            F.write("%s\t%s\n" % (k, stats[k]))
    
    return stats

def parseBam(seqInfo, inputFileName):

    basename = os.path.basename(inputFileName).replace('.bam', '')

    l.info('processing BAM file: %s' % inputFileName)
    l.info('Basename %s' % basename)

    readPairs = {}

    for seqId in seqInfo.keys():
        readPairs[seqId] = \
            { 'start1' : [],
              'stop1' : [],
              'start2' : [],
              'stop2' : [] }
        
    limit = options.limit
    if not limit:
        limit = 1e18

    #start processing bam file
    i = 0
    for seqid, start1, stop1, start2, stop2 in readBAM(inputFileName):
        i += 1
        if i > limit: break
        readPairs[seqid]['start1'].append(start1)
        readPairs[seqid]['stop1'].append(stop1)
        readPairs[seqid]['start2'].append(start2)
        readPairs[seqid]['stop2'].append(stop2)

    # process the sequences - turn everyting into np.arrays 
    # and write the data to numpy files - for quick reading in 
    # later stage -> for example, when fiddling with the statistics
    for seqId in seqInfo.keys():
        if not os.path.exists(seqId):
            os.mkdir(seqId)
        rp = readPairs[seqId]

        rp['start1'] = np.array(rp['start1'])
        rp['stop1'] = np.array(rp['stop1'])
        rp['start2'] = np.array(rp['start2'])
        rp['stop2'] = np.array(rp['stop2'])

        outname = os.path.join(seqId, basename + '.readpairs')
        np.savez(outname,
                 start1 = rp['start1'],  
                 stop1 = rp['stop1'],  
                 start2 = rp['start2'],  
                 stop2 = rp['stop2'])
        l.info('wrote %d pairs for %s to disk' % (len(rp['start1']),seqId))
    
    return readPairs

def normalizeSortReadPairs(bamBase, seqInfo, readPairs, stats):
    """
    normalize and sort the readpairs 
    
    normalize -> subtract the peak insert size so that
       all hover around zero

    sort into three groups: below zero, around zero and above zero

    We will do this per bamBase and per sequence
    """    

    for seqId in seqInfo.keys():

        l.info("start calculating coverage plots for %s" % seqId)

        rp = readPairs[seqId]
        seqLen = seqInfo[seqId]['length']

        l.debug("create coverage plot arrays")
        r_ok = np.zeros(seqLen, dtype=np.int)
        r_low = np.zeros(seqLen, dtype=np.int)
        r_high = np.zeros(seqLen, dtype=np.int)

        peakLow = stats['left']
        peakHigh = stats['right']

        def ff(a,b):
            dist = b-a
            if dist < peakLow:
                r_low[a:b] += 1
            elif dist > peakHigh:
                r_high[a:b] += 1
            else:
                r_ok[a:b] += 1
        FF=np.vectorize(ff)
        l.debug("Start calculating coverage plots for %d readpairs" % len(rp['start1']))
        FF(rp['start1'], rp['stop2'])
        l.debug("Done calculating coverage plot")
        
        #write the plots to disk      
        l.debug("Start wrinting coverage plot to disk")
        np.savez(os.path.join(seqId, bamBase + '.coverage'),
                 r_low = r_low, 
                 r_ok = r_ok, 
                 r_high = r_high)
        l.debug("wrote coverage plot to disk")

def readBamDataFromDisk(seqInfo, bamBase):
    readPairs = {}
    for seqId in seqInfo.keys():
        rp = {}
        datafile = os.path.join(seqId, bamBase + '.readpairs.npz')
        data = np.load(datafile)
        rp['start1'] = data['start1']
        rp['stop1'] = data['stop1']
        rp['start2'] = data['start2']
        rp['stop2'] = data['stop2']
        l.info('%d records from %s' % (rp['start1'].shape[1], seqId))
        readPairs[s] = rp
    return readPairs

def readStatsFromDisk(bamBase):
    stats = {}
    with open(os.path.join('stats', bamBase + '.stats'), 'r') as F:
        for  line in F.readlines():
            k, v = line.strip().split("\t")
            stats[k] = float(v)
    return stats

if __name__ == '__main__':

    for inputFile in inputFiles:
        bamBase = os.path.basename(inputFile).replace('.bam', '')
        l.info('processing bamfile %s' % bamBase)

        seqInfo = getSequenceInfo(inputFile)
        l.info('discovered %d sequences' % len(seqInfo))

        # should we pars the BAM files & or read intermediate files
        # from disk?
        if options.skipRead:
            l.info("skiping BAM parsing")
            readPairs = readBamDataFromDisk(seqInfo, bamBase)
        else:
            readPairs = parseBam(seqInfo, inputFile)

        # Should we do the stats? Or read the stats from disk??
        if options.skipStat:
            stats = readStatsFromDisk(bamBase)
            l.info("read stats, peak is at %.0f" % stats['top'])
        else:
            stats = doStats(bamBase, seqInfo, readPairs)

        #Sort the readpairs
        normalizeSortReadPairs(bamBase, seqInfo, readPairs, stats)
            
